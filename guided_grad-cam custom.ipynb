{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Backpropagation\n",
    "\n",
    "Guided backpropagation is a combination of the gradient and deconvolution attribution methods. The deconvolution method discussed in [Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](https://arxiv.org/abs/1312.6034), was shown to be equivalent to a backward pass through the network, except for its interaction with the relu layer. The negative gradient values would be zeroed by relu, but the gradient values coming from negative input image values were not zeroed. Guided backpropagation method adapts this idea by **zeroing both negative gradients and gradients coming from negative input values**. We will implement this method by introducing a new relu layer called guided relu. Unfortunately guided relu performs poorly when training, so the model will first be trained with relu layers, then the relu layers will be swapped out for the guided relu layers when evaluating the attribution maps. There is no obvious way to swap layers in flax, so instead we will define a new model with the same architecture but guided relu inplace of relu layers.  \n",
    "\n",
    "For more technical information on the guided backpropagation attribution method see: [Striving for Simplicity: The All Convolutional Net](https://arxiv.org/abs/1412.6806)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "import jax\n",
    "from jax import random\n",
    "from jax import grad\n",
    "import optax\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import flaxmodels\n",
    "from PIL import Image\n",
    "from flax.core.frozen_dict import freeze\n",
    "\n",
    "from utils.image import *\n",
    "from utils.plot import plot_image, plot_all_images\n",
    "from utils.guided_relu import guided_relu\n",
    "\n",
    "\n",
    "from utils.classification import get_predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'storage/datasets/imagenet/train/n01518878/n01518878_5.JPEG'\n",
    "import os\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "Check if the training data exists. If not, automatically download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = cv2.imread(image_path, 1)[:, :, ::-1] # `::-1`: Selects all channels but in reverse order, resulting in the RGB image.\n",
    "rgb_img = np.float32(rgb_img) / 255\n",
    "    \n",
    "preprocessed_img = preprocess_image(rgb_img)\n",
    "input_tensor = jnp.expand_dims(preprocessed_img, axis=0) # Whether to use preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "H, W, C = rgb_img.shape\n",
    "plot_image(rgb_img, title='Original Image')\n",
    "plot_image(preprocessed_img, title='Preprocessed Image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model with grad-cam hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = jnp.linspace(-5, 5, 1000)\n",
    "\n",
    "plt.plot(jnp.sin(input_vector))\n",
    "plt.plot(jax.vmap(grad(jnp.sin))(input_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_sin(x):\n",
    "    x = jax.nn.relu(x)\n",
    "    return jnp.sin(x)\n",
    "\n",
    "plt.plot(relu_sin(input_vector))\n",
    "plt.plot(jax.vmap(grad(relu_sin))(input_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guided_relu_sin(x):\n",
    "    x = guided_relu(x)\n",
    "    return jnp.sin(x)\n",
    "\n",
    "plt.plot(guided_relu_sin(input_vector))\n",
    "plt.plot(jax.vmap(grad(guided_relu_sin))(input_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_grad_cam_model = flaxmodels.ResNet50Guided(output='logits', pretrained='imagenet', customized_relu=guided_relu, use_observed_layer=True)\n",
    "vanilla_model = flaxmodels.ResNet50(output='logits', pretrained='imagenet')\n",
    "\n",
    "rng_key = random.PRNGKey(0)\n",
    "\n",
    "variables = guided_grad_cam_model.init(rng_key, input_tensor) # {'params': ..., 'batch_stats': ..., 'perturbations': ...}\n",
    "\n",
    "logits = guided_grad_cam_model.apply(variables, input_tensor, train=False)\n",
    "prediction = get_predictions(logits)\n",
    "print(prediction) # probabilities for 1000 classes\n",
    "\n",
    "# print(model.tabulate(rng_key, input_tensor))\n",
    "# print(variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_with_guided_relu = flaxmodels.ResNet50Guided(output='logits', pretrained='imagenet', )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display predictions and attribution maps\n",
    "\n",
    "The final convolutional layer values and gradients are required to perform Grad-CAM. To access the convolutional layer it needs to be stored as an intermediate variable in the model definition, then the \"mutable='intermediates'\" argument is supplied to the model when performing the forward pass. The gradients of the final convolutional layer is extracted by passing the final convolutional layers values as a perturbation parameter to the loss function, then calculating the gradients of the perturbation parameter. Global average pooling is then applied to the convolutional layers gradients to extract the weightings. This is performed by taking the mean of each filter/feature map, this results in a vector of floats with the size of the number of feature maps. The vector is then used as weights for the feature maps. The dot product is taken between the weights and feature maps to provide us with the class activation mapping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new loss function with guided model\n",
    "\n",
    "A new loss function containing the model with guided relu layers is required when performing gradient calculations for the attribution attribution maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, params, batch_stats, perturbations, X, Y):\n",
    "    '''\n",
    "    Classification loss function.\n",
    "    In both Guided BP and Grad-CAM , we want to get the grad of the last layer w.r.t. the target label, instead of the loss.\n",
    "    To do this, we still define the loss function, but we use the negated gradients, since d(-L) / dx == - d(L) / dx\n",
    "    '''\n",
    "    variables = {\n",
    "        'params': params,\n",
    "        'batch_stats': batch_stats,\n",
    "        'perturbations': perturbations\n",
    "    }\n",
    "    \n",
    "    logits = model.apply(variables, X, train=False)\n",
    "    predictions = get_predictions(logits)\n",
    "    \n",
    "    logit_for_pred = logits[0, predictions[0]]\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, Y)\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display predictions and attribution maps\n",
    "\n",
    "The gradients are calculated with the new guided loss function. The gradients are then normalized in the standard way for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, variables, X):\n",
    "    logits, state = model.apply(variables, X, train=False, mutable='intermediates')\n",
    "    predictions = get_predictions(logits)\n",
    "    return predictions, state\n",
    "\n",
    "    \n",
    "\n",
    "def display_prediction(model_with_observe, variables, rgb_img, input_tensor, vanilla_model, target=None):\n",
    "    prediction, state = make_predictions(model_with_observe, variables, input_tensor)\n",
    "    # Extract final conv layers values\n",
    "    final_conv_layer_activations = state[\"intermediates\"][\"gradcam_sow\"][0]\n",
    "    \n",
    "    if target is None:\n",
    "        target = prediction\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Target: \", target)\n",
    "    \n",
    "    # For input image\n",
    "    B, H, W, C = input_tensor.shape\n",
    "    assert B==1\n",
    "    plot_image(input_tensor[0], title='Preprocessed Image')\n",
    "    \n",
    "    \n",
    "    #################################################\n",
    "    # Grad-CAM\n",
    "    #################################################\n",
    "    perturbations = freeze({\"gradcam_perturb\": final_conv_layer_activations}) # This is the perturbation that we will use to extract the gradients.\n",
    "    final_conv_grads = grad(loss_fn, argnums=3)(model_with_observe, variables['params'], variables['batch_stats'], perturbations, input_tensor, target) # Use negated grad\n",
    "    final_conv_grads = -final_conv_grads[\"gradcam_perturb\"] # Here I use the negated gradients w.r.t. the classificaiton loss to get the positive contributions.\n",
    "    \n",
    "    # Get weights using global average pooling\n",
    "    weights = jnp.mean(final_conv_grads, axis=(1, 2))# (B, H', W', C') -> (B, H'*W'*C') \n",
    "    # Get the weighted sum of all the filters\n",
    "    \n",
    "    weighted_activations = weights[:, None, None, :] * final_conv_layer_activations \n",
    "    \n",
    "    target_size = (W, H)\n",
    "    cam = jnp.sum(weighted_activations, axis=-1) # (B, H', W', C')\n",
    "    cam = jnp.maximum(cam, 0) # They take only the positive contributions by applying a RELU function:\n",
    "    scaled = scale_cam_image(cam, target_size) # (B, H, W)\n",
    "    \n",
    "    grayscale_cam = scaled[0, :]\n",
    "    #################################################\n",
    "    #################################################\n",
    "    \n",
    "    # After Grad-CAM, we need to clear intermediates to avoid feed it back into `variables`. \n",
    "    # See https://flax.readthedocs.io/en/latest/guides/model_inspection/extracting_intermediates.html\n",
    "    perturbations  = {key: jnp.zeros_like(value) for key, value in perturbations.items()}\n",
    "    \n",
    "    #################################################\n",
    "    # Vanila Gradient Method\n",
    "    #################################################\n",
    "    attributions = -grad(loss_fn, argnums=4)(vanilla_model, variables['params'], variables['batch_stats'], perturbations, input_tensor, target) # negated grad\n",
    "    attributions = attributions[0, :]\n",
    "    #################################################\n",
    "    #################################################\n",
    "    \n",
    "    \n",
    "    #################################################\n",
    "    # Guided BP \n",
    "    #################################################\n",
    "    attributions_guided = -grad(loss_fn, argnums=4)(model_with_observe, variables['params'], variables['batch_stats'], perturbations, input_tensor, target) # negated grad\n",
    "    attributions_guided = attributions_guided[0, :]\n",
    "    #################################################\n",
    "    #################################################\n",
    "    \n",
    "    \n",
    "    #################################################\n",
    "    # Guided Grad-CAM\n",
    "    #################################################\n",
    "    cam_mask = cv2.merge([grayscale_cam, grayscale_cam, grayscale_cam])\n",
    "    guided_cam_image = cam_mask * attributions_guided\n",
    "    #################################################\n",
    "    #################################################\n",
    "    \n",
    "    # Visualization\n",
    "    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "    attributions = deprocess_image(attributions)\n",
    "    attributions_guided = deprocess_image(attributions_guided)\n",
    "    guided_cam_image = deprocess_image(guided_cam_image)\n",
    "\n",
    "    plot_all_images(cam_image, attributions, attributions_guided, guided_cam_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction(guided_grad_cam_model, variables, rgb_img, input_tensor, vanilla_model, target=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('flax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a8d1f2580cdfde5c5829808ec6fccc81a351d243fb8b1925f7928e44ccf575b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
